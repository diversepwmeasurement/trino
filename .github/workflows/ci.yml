concurrency:
  cancel-in-progress: true
  group: 'workflow=${{ github.workflow }},

    pr_number=${{ github.event_name == ''pull_request'' && github.event.number ||
    ''NA'' }},

    dispatch_sha=${{ github.event_name == ''repository_dispatch'' && github.event.client_payload.slash_command.args.named.sha
    || ''NA'' }},

    commit_sha=${{ github.event_name != ''pull_request'' && github.event_name != ''repository_dispatch''
    && github.sha || ''NA'' }}

    '
defaults:
  run:
    shell: bash --noprofile --norc -euo pipefail {0}
env:
  CI_SKIP_SECRETS_PRESENCE_CHECKS: ${{ secrets.CI_SKIP_SECRETS_PRESENCE_CHECKS }}
  CONTINUOUS_INTEGRATION: true
  MAVEN: ./mvnw
  MAVEN_COMPILE_COMMITS: -B --quiet -T 1C -DskipTests -Dmaven.source.skip=true -Dair.check.skip-all=true
    -Dmaven.javadoc.skip=true --no-snapshot-updates --no-transfer-progress -pl '!:trino-server-rpm'
  MAVEN_FAST_INSTALL: -B -V --quiet -T 1C -DskipTests -Dmaven.source.skip=true -Dair.check.skip-all
  MAVEN_GIB: -P gib -Dgib.referenceBranch=refs/remotes/origin/${{ github.event_name
    == 'pull_request' && github.event.pull_request.base.ref || github.event.repository.default_branch
    }}
  MAVEN_INSTALL_OPTS: -Xmx3G -XX:+ExitOnOutOfMemoryError
  MAVEN_OPTS: -Xmx512M -XX:+ExitOnOutOfMemoryError
  MAVEN_TEST: -B -Dmaven.source.skip=true -Dair.check.skip-all --fail-at-end -P gib
    -Dgib.referenceBranch=refs/remotes/origin/${{ github.event_name == 'pull_request'
    && github.event.pull_request.base.ref || github.event.repository.default_branch
    }}
  PTL_TMP_DOWNLOAD_PATH: /tmp/pt_java_downloads
  SECRETS_PRESENT: ${{ secrets.SECRETS_PRESENT }}
  SEGMENT_DOWNLOAD_TIMEOUT_MINS: 5
  TESTCONTAINERS_PULL_PAUSE_TIMEOUT: 600
jobs:
  artifact-checks:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      timeout-minutes: 10
      uses: ./.github/actions/setup
      with:
        cache: restore
        cleanup-node: true
    - continue-on-error: true
      name: Maven Install
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN clean install ${MAVEN_FAST_INSTALL} -pl ''!:trino-docs,!:trino-server-rpm''

        '
    - continue-on-error: true
      name: Test Server RPM
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN verify -B --strict-checksums -P ci -pl :trino-server-rpm

        '
    - continue-on-error: true
      name: Test JDBC shading
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN failsafe:integration-test failsafe:verify -B --strict-checksums -P
        ci -pl :trino-jdbc

        '
    - continue-on-error: true
      name: Clean Maven Output
      run: $MAVEN clean -pl '!:trino-server,!:trino-cli'
    - continue-on-error: true
      uses: docker/setup-qemu-action@68827325e0b33c7199eb31dd4e31fbe9023e06e3
      with:
        platforms: arm64,ppc64le
    - continue-on-error: true
      name: Build and Test Docker Image
      run: core/docker/build.sh
    timeout-minutes: 45
  build-pt:
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      product-tests-changed: ${{ steps.filter.outputs.product-tests }}
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      timeout-minutes: 10
      uses: ./.github/actions/setup
      with:
        cache: restore
        cleanup-node: true
    - continue-on-error: true
      id: filter
      uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36
      with:
        filters: "product-tests:\n  - 'testing/trino-product-tests*/**'\n  - 'testing/trino-testing-services/**'\n\
          \  # run all tests when there are any changes in the trino-server Maven\
          \ module\n  # because it doesn't define it's Trino dependencies and\n  #\
          \ it relies on the Provisio plugin to find the right artifacts\n  - 'core/trino-server/**'\n\
          \  - '.github/**'\n"
    - continue-on-error: true
      name: Maven Install
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN clean install ${MAVEN_FAST_INSTALL} -pl ''!:trino-docs,!:trino-server-rpm''

        '
    - continue-on-error: true
      name: Map impacted plugins to features
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        # build a list of impacted modules, ignoring modules that cannot affect either
        product tests or Trino

        $MAVEN validate ${MAVEN_FAST_INSTALL} ${MAVEN_GIB} -Dgib.logImpactedTo=gib-impacted.log
        -pl ''!:trino-docs,!:trino-tests,!:trino-faulttolerant-tests''

        # GIB doesn''t run on master, so make sure the file always exist

        touch gib-impacted.log

        testing/trino-plugin-reader/target/trino-plugin-reader-*-executable.jar -i
        gib-impacted.log -p core/trino-server/target/trino-server-*-hardlinks/plugin
        > impacted-features.log

        echo "Impacted plugin features:"

        cat impacted-features.log

        '
    - continue-on-error: true
      name: Product tests artifact
      uses: actions/upload-artifact@v4
      with:
        name: product tests and server tarball
        path: 'core/trino-server/target/*.tar.gz

          impacted-features.log

          testing/trino-product-tests-launcher/target/*.jar

          testing/trino-product-tests/target/*-executable.jar

          client/trino-cli/target/*-executable.jar

          '
        retention-days: 1
    - continue-on-error: true
      id: prepare-matrix-template
      run: "cat <<EOF > .github/test-pt-matrix.yaml\nconfig:\n  - default\nsuite:\n\
        \  - suite-1\n  - suite-2\n  - suite-3\n  # suite-4 does not exist\n  - suite-5\n\
        \  - suite-6-non-generic\n  - suite-7-non-generic\n  - suite-hive-transactional\n\
        \  - suite-azure\n  - suite-delta-lake-databricks91\n  - suite-delta-lake-databricks104\n\
        \  - suite-delta-lake-databricks113\n  - suite-delta-lake-databricks122\n\
        \  - suite-delta-lake-databricks133\n  - suite-databricks-unity-http-hms\n\
        \  - suite-gcs\n  - suite-clients\n  - suite-functions\n  - suite-tpch\n \
        \ - suite-tpcds\n  - suite-storage-formats-detailed\n  - suite-parquet\n \
        \ - suite-oauth2\n  - suite-ldap\n  - suite-compatibility\n  - suite-all-connectors-smoke\n\
        \  - suite-delta-lake-oss\n  - suite-kafka\n  - suite-cassandra\n  - suite-clickhouse\n\
        \  - suite-mysql\n  - suite-iceberg\n  - suite-snowflake\n  - suite-hudi\n\
        \  - suite-ignite\nexclude:\n  - suite: suite-azure\n    ignore exclusion\
        \ if: >-\n      ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' ||\n       \
        \   vars.AZURE_ABFS_HIERARCHICAL_CONTAINER != '' ||\n          vars.AZURE_ABFS_HIERARCHICAL_ACCOUNT\
        \ != '' ||\n          secrets.AZURE_ABFS_HIERARCHICAL_ACCESS_KEY != '' }}\n\
        \n  - suite: suite-gcs\n    ignore exclusion if: >-\n      ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS\
        \ != '' || secrets.GCP_CREDENTIALS_KEY != '' }}\n\n  - suite: suite-delta-lake-databricks91\n\
        \    ignore exclusion if: >-\n      ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS\
        \ != '' || secrets.DATABRICKS_TOKEN != '' }}\n  - suite: suite-delta-lake-databricks104\n\
        \    ignore exclusion if: >-\n      ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS\
        \ != '' || secrets.DATABRICKS_TOKEN != '' }}\n  - suite: suite-delta-lake-databricks113\n\
        \    ignore exclusion if: >-\n      ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS\
        \ != '' || secrets.DATABRICKS_TOKEN != '' }}\n  - suite: suite-delta-lake-databricks122\n\
        \    ignore exclusion if: >-\n      ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS\
        \ != '' || secrets.DATABRICKS_TOKEN != '' }}\n  - suite: suite-delta-lake-databricks133\n\
        \    ignore exclusion if: >-\n      ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS\
        \ != '' || secrets.DATABRICKS_TOKEN != '' }}\n  - suite: suite-databricks-unity-http-hms\n\
        \    config: hdp3\n  - suite: suite-databricks-unity-http-hms\n    ignore\
        \ exclusion if: >-\n      ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' ||\
        \ secrets.DATABRICKS_TOKEN != '' }}\n  - suite: suite-snowflake\n    ignore\
        \ exclusion if: >-\n      ${{ env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' ||\
        \ secrets.SNOWFLAKE_PASSWORD != '' }}\n\nignore exclusion if:\n  # Do not\
        \ use this property outside of the matrix configuration.\n  #\n  # This is\
        \ added to all matrix entries so they may be conditionally\n  # excluded by\
        \ adding them to the excludes list with a GHA expression\n  # for this property.\n\
        \  # - If the expression evaluates to true, it will never match the a\n  #\
        \   actual value of the property, and will therefore not be excluded.\n  #\
        \ - If the expression evaluates to false, it will match the actual\n  #  \
        \ value of the property, and the exclusion will apply normally.\n  - \"false\"\
        \ninclude:\n  # this suite is designed specifically for apache-hive3. TODO\
        \ remove the suite once we can run all regular tests on apache-hive3.\n  -\
        \ config: apache-hive3\n    suite: suite-hms-only\nEOF\n"
    - continue-on-error: true
      if: 'github.event_name != ''pull_request'' ||

        steps.filter.outputs.product-tests == ''true'' ||

        contains(github.event.pull_request.labels.*.name, ''tests:all'') ||

        contains(github.event.pull_request.labels.*.name, ''tests:all-product'')

        '
      name: Build PT matrix (all)
      run: '# converts entire YAML file into JSON - no filtering since we want all
        PTs to run

        ./.github/bin/build-pt-matrix-from-impacted-connectors.py -v -m .github/test-pt-matrix.yaml
        -o matrix.json

        '
    - continue-on-error: true
      env:
        ABFS_ACCESS_KEY: ''
        ABFS_ACCOUNT: ''
        ABFS_CONTAINER: ''
        AWS_REGION: ''
        DATABRICKS_104_JDBC_URL: ''
        DATABRICKS_113_JDBC_URL: ''
        DATABRICKS_122_JDBC_URL: ''
        DATABRICKS_133_JDBC_URL: ''
        DATABRICKS_91_JDBC_URL: ''
        DATABRICKS_HOST: ''
        DATABRICKS_LOGIN: ''
        DATABRICKS_TOKEN: ''
        DATABRICKS_UNITY_CATALOG_NAME: ''
        DATABRICKS_UNITY_EXTERNAL_LOCATION: ''
        DATABRICKS_UNITY_JDBC_URL: ''
        GCP_CREDENTIALS_KEY: ''
        GCP_STORAGE_BUCKET: ''
        S3_BUCKET: ''
        SNOWFLAKE_DATABASE: ''
        SNOWFLAKE_PASSWORD: ''
        SNOWFLAKE_ROLE: ''
        SNOWFLAKE_URL: ''
        SNOWFLAKE_USER: ''
        SNOWFLAKE_WAREHOUSE: ''
        TESTCONTAINERS_NEVER_PULL: true
        TRINO_AWS_ACCESS_KEY_ID: ''
        TRINO_AWS_SECRET_ACCESS_KEY: ''
      if: 'github.event_name == ''pull_request'' &&

        steps.filter.outputs.product-tests == ''false'' &&

        !contains(github.event.pull_request.labels.*.name, ''tests:all'') &&

        !contains(github.event.pull_request.labels.*.name, ''product-tests:all'')

        '
      name: Build PT matrix (impacted-features)
      run: '# converts filtered YAML file into JSON

        ./.github/bin/build-pt-matrix-from-impacted-connectors.py -v -m .github/test-pt-matrix.yaml
        -i impacted-features.log -o matrix.json

        '
    - continue-on-error: true
      id: set-matrix
      run: 'echo "Matrix: $(jq ''.'' matrix.json)"

        echo "matrix=$(cat matrix.json)" >> $GITHUB_OUTPUT

        '
  build-test-matrix:
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      timeout-minutes: 10
      uses: ./.github/actions/setup
      with:
        cache: restore
    - continue-on-error: true
      if: github.event_name == 'repository_dispatch' && github.event.client_payload.slash_command.args.named.sha
        != '' && github.event.client_payload.pull_request.head.sha == github.event.client_payload.slash_command.args.named.sha
      name: Update PR check
      uses: ./.github/actions/update-check
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        pull_request_number: ${{ github.event.client_payload.pull_request.number }}
    - continue-on-error: true
      name: Maven validate
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN validate ${MAVEN_FAST_INSTALL} ${MAVEN_GIB} -Dgib.logImpactedTo=gib-impacted.log
        -P disable-check-spi-dependencies -pl ''!:trino-docs''

        '
    - continue-on-error: true
      id: set-matrix
      name: Set matrix
      run: "# GIB doesn't run on master, so make sure the file always exist\ntouch\
        \ gib-impacted.log\ncat <<EOF > .github/test-matrix.yaml\ninclude:\n  - modules:\n\
        \      - client/trino-jdbc\n      - plugin/trino-base-jdbc\n      - plugin/trino-memory\n\
        \      - plugin/trino-thrift\n  - modules:\n      - lib/trino-orc\n      -\
        \ lib/trino-parquet\n  - modules:\n      - lib/trino-filesystem\n      - lib/trino-filesystem-azure\n\
        \      - lib/trino-filesystem-manager\n      - lib/trino-filesystem-s3\n \
        \     - lib/trino-hdfs\n  - { modules: core/trino-main }\n  - { modules: lib/trino-filesystem-azure,\
        \ profile: cloud-tests }\n  - { modules: lib/trino-filesystem-gcs, profile:\
        \ cloud-tests }\n  - { modules: lib/trino-filesystem-s3, profile: cloud-tests\
        \ }\n  - { modules: lib/trino-hdfs, profile: cloud-tests }\n  - { modules:\
        \ plugin/trino-accumulo }\n  - { modules: plugin/trino-bigquery }\n  - { modules:\
        \ plugin/trino-bigquery, profile: cloud-tests-2 }\n  - { modules: plugin/trino-cassandra\
        \ }\n  - { modules: plugin/trino-clickhouse }\n  - { modules: plugin/trino-delta-lake\
        \ }\n  - { modules: plugin/trino-delta-lake, profile: cloud-tests }\n  - {\
        \ modules: plugin/trino-delta-lake, profile: fte-tests }\n  - { modules: plugin/trino-druid\
        \ }\n  - { modules: plugin/trino-elasticsearch }\n  - { modules: plugin/trino-google-sheets\
        \ }\n  - { modules: plugin/trino-hive }\n  - { modules: plugin/trino-hive,\
        \ profile: fte-tests }\n  - { modules: plugin/trino-hive, profile: test-parquet\
        \ }\n  - { modules: plugin/trino-hudi }\n  - { modules: plugin/trino-iceberg\
        \ }\n  - { modules: plugin/trino-iceberg, profile: cloud-tests }\n  - { modules:\
        \ plugin/trino-iceberg, profile: fte-tests }\n  - { modules: plugin/trino-iceberg,\
        \ profile: minio-and-avro }\n  - { modules: plugin/trino-ignite }\n  - { modules:\
        \ plugin/trino-kafka }\n  - { modules: plugin/trino-kudu }\n  - { modules:\
        \ plugin/trino-mariadb }\n  - { modules: plugin/trino-mongodb }\n  - { modules:\
        \ plugin/trino-mysql }\n  - { modules: plugin/trino-openlineage }\n  - { modules:\
        \ plugin/trino-opensearch }\n  - { modules: plugin/trino-oracle }\n  - { modules:\
        \ plugin/trino-phoenix5 }\n  - { modules: plugin/trino-pinot }\n  - { modules:\
        \ plugin/trino-postgresql }\n  - { modules: plugin/trino-raptor-legacy }\n\
        \  - { modules: plugin/trino-redis }\n  - { modules: plugin/trino-redshift\
        \ }\n  - { modules: plugin/trino-redshift, profile: cloud-tests }\n  - { modules:\
        \ plugin/trino-redshift, profile: fte-tests }\n  - { modules: plugin/trino-resource-group-managers\
        \ }\n  - { modules: plugin/trino-singlestore }\n  - { modules: plugin/trino-snowflake\
        \ }\n  - { modules: plugin/trino-snowflake, profile: cloud-tests }\n  - {\
        \ modules: plugin/trino-sqlserver }\n  - { modules: testing/trino-faulttolerant-tests,\
        \ profile: default }\n  - { modules: testing/trino-faulttolerant-tests, profile:\
        \ test-fault-tolerant-delta }\n  - { modules: testing/trino-faulttolerant-tests,\
        \ profile: test-fault-tolerant-hive }\n  - { modules: testing/trino-faulttolerant-tests,\
        \ profile: test-fault-tolerant-iceberg }\n  - { modules: testing/trino-tests\
        \ }\nEOF\n./.github/bin/build-matrix-from-impacted.py -v -i gib-impacted.log\
        \ -m .github/test-matrix.yaml -o matrix.json\necho \"Matrix: $(jq '.' matrix.json)\"\
        \necho \"matrix=$(jq -c '.' matrix.json)\" >> $GITHUB_OUTPUT\n"
  check-commit:
    if: github.event_name == 'pull_request' && needs.check-commits-dispatcher.outputs.matrix
      != ''
    needs: check-commits-dispatcher
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      if: matrix.commit != ''
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: ${{ matrix.commit }}
    - continue-on-error: true
      if: matrix.commit != ''
      uses: ./.github/actions/compile-commit
      with:
        base_ref: ${{ github.event.pull_request.base.ref }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.check-commits-dispatcher.outputs.matrix) }}
  check-commits-dispatcher:
    if: github.event_name == 'pull_request'
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    - continue-on-error: true
      name: Block illegal commits
      uses: trinodb/github-actions/block-commits@c2991972560c5219d9ae5fb68c0c9d687ffcdd10
      with:
        action-fixup: none
        action-merge: fail
    - continue-on-error: true
      id: set-matrix
      name: Set matrix (dispatch commit checks)
      run: "# Make sure the PR branch contains the compile-commit composite job\n\
        if git merge-base --is-ancestor $( git rev-list HEAD -- .github/actions/compile-commit/action.yml\
        \ | tail -n 1 ) ${{ github.event.pull_request.head.sha }}\nthen\n  # The HEAD\
        \ commit of the PR can be safely ignored since it's already compiled in other\
        \ jobs\n  # This is achieved by adding a tilde (~) after the HEAD sha\n  git\
        \ log --reverse --pretty=format:'%H,%T,\"%s\"' refs/remotes/origin/${{ github.event.pull_request.base.ref\
        \ }}..${{ github.event.pull_request.head.sha }}~ | ./.github/bin/prepare-check-commits-matrix.py\
        \ > commit-matrix.json\nelse\n  echo -n '' > commit-matrix.json\nfi\n\necho\
        \ \"Commit matrix: $(jq '.' commit-matrix.json)\"\necho \"matrix=$(jq -c '.'\
        \ commit-matrix.json)\" >> $GITHUB_OUTPUT\n"
  error-prone-checks:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      timeout-minutes: 10
      uses: ./.github/actions/setup
      with:
        cache: restore
    - continue-on-error: true
      name: Maven Install
      run: '# build everything to make sure dependencies of impacted modules are present

        export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN clean install ${MAVEN_FAST_INSTALL} ${MAVEN_GIB} -pl ''!:trino-docs,!:trino-server,!:trino-server-rpm''

        '
    - continue-on-error: true
      name: Error Prone Checks
      run: "export MAVEN_OPTS=\"${MAVEN_INSTALL_OPTS}\"\n# Skip checks, these are\
        \ run in `maven-checks` job and e.g. checkstyle is expensive.\n$MAVEN ${MAVEN_TEST}\
        \ -T 1C clean verify -DskipTests -Dair.check.skip-all=true ${MAVEN_GIB} -Dgib.buildUpstream=never\
        \ -P errorprone-compiler \\\n  -pl '!:trino-docs,!:trino-server,!:trino-server-rpm'\n"
    timeout-minutes: 45
  hive-tests:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      timeout-minutes: 10
      uses: ./.github/actions/setup
      with:
        cache: restore
    - continue-on-error: true
      name: Install Hive Module
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN clean install ${MAVEN_FAST_INSTALL} ${MAVEN_GIB} -Dgib.logImpactedTo=gib-impacted.log
        -am -pl :trino-hive

        '
    - continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ vars.TRINO_AWS_ACCESS_KEY_ID }}
        AWS_REGION: ${{ vars.TRINO_AWS_REGION }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.TRINO_AWS_SECRET_ACCESS_KEY }}
        S3_BUCKET: ${{ vars.TRINO_S3_BUCKET }}
        S3_BUCKET_ENDPOINT: s3.${{ vars.TRINO_AWS_REGION }}.amazonaws.com
      id: tests
      name: Run Hive AWS Tests
      run: "if [ \"${AWS_ACCESS_KEY_ID}\" != \"\" ] && ( [ ! -f gib-impacted.log ]\
        \ || grep -q plugin/trino-hive gib-impacted.log ); then\n  $MAVEN test ${MAVEN_TEST}\
        \ -pl :trino-hive -P aws-tests\nfi\n"
    - continue-on-error: true
      env:
        DATABRICKS_HOST: ${{ vars.TRINO_DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.TRINO_DATABRICKS_TOKEN }}
        DATABRICKS_UNITY_CATALOG_NAME: ${{ vars.TRINO_DATABRICKS_UNITY_CATALOG_NAME
          }}
      id: test-unity
      name: Run Hive Unity Tests
      run: "if [ \"${DATABRICKS_TOKEN}\" != \"\" ] && ( [ ! -f gib-impacted.log ]\
        \ || grep -q plugin/trino-hive gib-impacted.log ); then\n  $MAVEN test ${MAVEN_TEST}\
        \ -pl :trino-hive -P unity-tests\nfi\n"
    - continue-on-error: true
      if: always()
      name: Upload test results
      uses: ./.github/actions/process-test-results
      with:
        has-failed-tests: ${{ steps.tests.outcome == 'failure' }}
        upload-heap-dump: ${{ env.SECRETS_PRESENT == '' && github.event_name == 'pull_request'
          && github.event.pull_request.head.repo.full_name != github.repository }}
    - continue-on-error: true
      if: failure() && github.event_name == 'repository_dispatch' && github.event.client_payload.slash_command.args.named.sha
        != '' && github.event.client_payload.pull_request.head.sha == github.event.client_payload.slash_command.args.named.sha
      name: Update PR check
      uses: ./.github/actions/update-check
      with:
        check_name: ${{ github.job }} (${{ matrix.config }}) with secrets
        conclusion: ${{ job.status }}
        github_token: ${{ secrets.GITHUB_TOKEN }}
        pull_request_number: ${{ github.event.client_payload.pull_request.number }}
    strategy:
      fail-fast: false
      matrix:
        config:
        - config-hdp3
    timeout-minutes: 60
  maven-checks:
    name: maven-checks ${{ matrix.java-version }}
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      timeout-minutes: 10
      uses: ./.github/actions/setup
      with:
        cache: ${{ matrix.cache }}
        cleanup-node: ${{ matrix.cleanup-node }}
        java-version: ${{ matrix.java-version }}
    - continue-on-error: true
      name: Check SPI backward compatibility
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN clean install ${MAVEN_FAST_INSTALL} -pl :trino-spi -am

        $MAVEN clean verify -B --strict-checksums -DskipTests -pl :trino-spi

        '
    - continue-on-error: true
      name: Maven Checks
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN clean verify -B --strict-checksums -V -T 1C -DskipTests -P ci -pl ''!:trino-server-rpm''

        '
    - continue-on-error: true
      if: steps.cache.outputs.cache-hit != 'true' && matrix.cache == 'true'
      name: Remove Trino from local Maven repo to avoid caching it
      run: rm -rf ~/.m2/repository/io/trino/trino-*
    strategy:
      fail-fast: false
      matrix:
        include:
        - cache: 'true'
          cleanup-node: false
          java-version: 22
        - cache: restore
          cleanup-node: true
          java-version: 23-ea
    timeout-minutes: 45
  pt:
    if: needs.build-pt.outputs.matrix != '{}'
    name: pt (${{ matrix.config }}, ${{ matrix.suite }}, ${{ matrix.jdk }})
    needs: build-pt
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      timeout-minutes: 10
      uses: ./.github/actions/setup
      with:
        cache: 'false'
    - continue-on-error: true
      name: Product tests artifact
      uses: actions/download-artifact@v4
      with:
        name: product tests and server tarball
    - continue-on-error: true
      name: Fix artifact permissions
      run: 'find . -type f -name \*-executable.jar -exec chmod 0777 {} \;

        '
    - continue-on-error: true
      if: 'needs.build-pt.outputs.product-tests-changed == ''false'' &&

        github.event_name == ''pull_request'' &&

        !contains(github.event.pull_request.labels.*.name, ''tests:all'') &&

        !contains(github.event.pull_request.labels.*.name, ''tests:all-product'')

        '
      name: Enable impact analysis
      run: echo "PTL_OPTS=--impacted-features impacted-features.log" >> $GITHUB_ENV
    - continue-on-error: true
      env:
        ABFS_ACCESS_KEY: ${{ secrets.AZURE_ABFS_HIERARCHICAL_ACCESS_KEY }}
        ABFS_ACCOUNT: ${{ vars.AZURE_ABFS_HIERARCHICAL_ACCOUNT }}
        ABFS_CONTAINER: ${{ vars.AZURE_ABFS_HIERARCHICAL_CONTAINER }}
        AWS_REGION: ${{ vars.TRINO_AWS_REGION }}
        DATABRICKS_104_JDBC_URL: ${{ vars.DATABRICKS_104_JDBC_URL }}
        DATABRICKS_113_JDBC_URL: ${{ vars.DATABRICKS_113_JDBC_URL }}
        DATABRICKS_122_JDBC_URL: ${{ vars.DATABRICKS_122_JDBC_URL }}
        DATABRICKS_133_JDBC_URL: ${{ vars.DATABRICKS_133_JDBC_URL }}
        DATABRICKS_91_JDBC_URL: ${{ vars.DATABRICKS_91_JDBC_URL }}
        DATABRICKS_HOST: ${{ vars.DATABRICKS_HOST }}
        DATABRICKS_LOGIN: token
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        DATABRICKS_UNITY_CATALOG_NAME: ${{ vars.DATABRICKS_UNITY_CATALOG_NAME }}
        DATABRICKS_UNITY_EXTERNAL_LOCATION: ${{ vars.DATABRICKS_UNITY_EXTERNAL_LOCATION
          }}
        DATABRICKS_UNITY_JDBC_URL: ${{ vars.DATABRICKS_UNITY_JDBC_URL }}
        GCP_CREDENTIALS_KEY: ${{ secrets.GCP_CREDENTIALS_KEY }}
        GCP_STORAGE_BUCKET: ${{ vars.GCP_STORAGE_BUCKET }}
        S3_BUCKET: ${{ vars.TRINO_S3_BUCKET }}
        SNOWFLAKE_DATABASE: ${{ vars.SNOWFLAKE_DATABASE }}
        SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        SNOWFLAKE_ROLE: ${{ vars.SNOWFLAKE_ROLE }}
        SNOWFLAKE_URL: ${{ vars.SNOWFLAKE_URL }}
        SNOWFLAKE_USER: ${{ vars.SNOWFLAKE_USER }}
        SNOWFLAKE_WAREHOUSE: ${{ vars.SNOWFLAKE_WAREHOUSE }}
        TRINO_AWS_ACCESS_KEY_ID: ${{ vars.TRINO_AWS_ACCESS_KEY_ID }}
        TRINO_AWS_SECRET_ACCESS_KEY: ${{ secrets.TRINO_AWS_SECRET_ACCESS_KEY }}
      name: Product Tests
      run: "exec testing/trino-product-tests-launcher/target/trino-product-tests-launcher-*-executable.jar\
        \ suite run \\\n  --suite ${{ matrix.suite }} \\\n  --config config-${{ matrix.config\
        \ }} \\\n  ${PTL_OPTS:-} \\\n  --bind=off --logs-dir logs/ --timeout 2h\n"
    - continue-on-error: true
      if: always()
      name: Upload test results
      uses: ./.github/actions/process-test-results
      with:
        artifact-name: pt (${{ matrix.config }}, ${{ matrix.suite }}, ${{ matrix.jdk
          }})
        has-failed-tests: ${{ steps.tests.outcome == 'failure' }}
        upload-heap-dump: ${{ env.SECRETS_PRESENT == '' && github.event_name == 'pull_request'
          && github.event.pull_request.head.repo.full_name != github.repository }}
    - continue-on-error: true
      if: failure() && github.event_name == 'repository_dispatch' && github.event.client_payload.slash_command.args.named.sha
        != '' && github.event.client_payload.pull_request.head.sha == github.event.client_payload.slash_command.args.named.sha
      name: Update PR check
      uses: ./.github/actions/update-check
      with:
        check_name: ${{ github.job }} with secrets
        conclusion: ${{ job.status }}
        github_token: ${{ secrets.GITHUB_TOKEN }}
        pull_request_number: ${{ github.event.client_payload.pull_request.number }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.build-pt.outputs.matrix) }}
    timeout-minutes: 130
  test:
    if: needs.build-test-matrix.outputs.matrix != '{}'
    needs: build-test-matrix
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      timeout-minutes: 10
      uses: ./.github/actions/setup
      with:
        cache: restore
        cleanup-node: ${{ format('{0}', matrix.modules == 'plugin/trino-singlestore')
          }}
        java-version: ${{ matrix.jdk != '' && matrix.jdk || '22' }}
    - continue-on-error: true
      name: Maven Install
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN clean install ${MAVEN_FAST_INSTALL} ${MAVEN_GIB} -am -pl "${{ matrix.modules
        }}"

        '
    - continue-on-error: true
      id: tests
      if: matrix.modules != 'plugin/trino-singlestore' && ! (contains(matrix.modules,
        'trino-bigquery') && contains(matrix.profile, 'cloud-tests-2')) && ! (contains(matrix.modules,
        'trino-delta-lake') && contains(matrix.profile, 'cloud-tests')) && ! (contains(matrix.modules,
        'trino-iceberg') && contains(matrix.profile, 'cloud-tests')) && ! (contains(matrix.modules,
        'trino-redshift') && contains(matrix.profile, 'cloud-tests')) && ! (contains(matrix.modules,
        'trino-redshift') && contains(matrix.profile, 'fte-tests')) && ! (contains(matrix.modules,
        'trino-snowflake') && contains(matrix.profile, 'cloud-tests')) && ! (contains(matrix.modules,
        'trino-filesystem-azure') && contains(matrix.profile, 'cloud-tests')) && !
        (contains(matrix.modules, 'trino-filesystem-gcs') && contains(matrix.profile,
        'cloud-tests')) && ! (contains(matrix.modules, 'trino-filesystem-s3') && contains(matrix.profile,
        'cloud-tests')) && ! (contains(matrix.modules, 'trino-hdfs') && contains(matrix.profile,
        'cloud-tests'))
      name: Maven Tests
      run: $MAVEN test ${MAVEN_TEST} -pl ${{ matrix.modules }} ${{ matrix.profile
        != '' && format('-P {0}', matrix.profile) || '' }}
    - continue-on-error: true
      id: tests-hdfs-isolated
      if: contains(matrix.modules, 'trino-hdfs')
      name: HDFS file system cache isolated JVM tests
      run: '$MAVEN test ${MAVEN_TEST} -pl :trino-hdfs -P test-isolated-jvm-suites

        '
    - continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ vars.TRINO_AWS_ACCESS_KEY_ID }}
        AWS_REGION: ${{ vars.TRINO_AWS_REGION }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.TRINO_AWS_SECRET_ACCESS_KEY }}
        S3_BUCKET: ${{ vars.TRINO_S3_BUCKET }}
        S3_BUCKET_ENDPOINT: s3.${{ vars.TRINO_AWS_REGION }}.amazonaws.com
      id: tests-hdfs
      if: contains(matrix.modules, 'trino-hdfs') && contains(matrix.profile, 'cloud-tests')
        && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || env.AWS_ACCESS_KEY_ID !=
        '' || env.AWS_SECRET_ACCESS_KEY != '')
      name: Hadoop FileSystem Cloud Tests
      run: '$MAVEN test ${MAVEN_TEST} -pl :trino-hdfs -P cloud-tests

        '
    - continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ vars.TRINO_AWS_ACCESS_KEY_ID }}
        AWS_REGION: ${{ vars.TRINO_AWS_REGION }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.TRINO_AWS_SECRET_ACCESS_KEY }}
      id: tests-s3
      if: contains(matrix.modules, 'trino-filesystem-s3') && contains(matrix.profile,
        'cloud-tests') && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || env.AWS_ACCESS_KEY_ID
        != '' || env.AWS_SECRET_ACCESS_KEY != '')
      name: S3 FileSystem Cloud Tests
      run: '# Create an empty S3 bucket for S3 filesystem cloud tests and add the
        bucket name to GitHub environment variables

        .github/bin/s3/setup-empty-s3-bucket.sh

        EMPTY_S3_BUCKET=$(cat .github/bin/s3/.bucket-identifier)

        export EMPTY_S3_BUCKET

        $MAVEN test ${MAVEN_TEST} -pl ${{ matrix.modules }} ${{ format(''-P {0}'',
        matrix.profile) }}

        '
    - continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ vars.TRINO_AWS_ACCESS_KEY_ID }}
        AWS_REGION: ${{ vars.TRINO_AWS_REGION }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.TRINO_AWS_SECRET_ACCESS_KEY }}
      if: always()
      name: Cleanup ephemeral S3 buckets
      run: .github/bin/s3/delete-s3-bucket.sh || true
    - continue-on-error: true
      env:
        ABFS_FLAT_ACCESS_KEY: ${{ secrets.AZURE_ABFS_FLAT_ACCESS_KEY }}
        ABFS_FLAT_ACCOUNT: ${{ vars.AZURE_ABFS_FLAT_ACCOUNT }}
        ABFS_HIERARCHICAL_ACCESS_KEY: ${{ secrets.AZURE_ABFS_HIERARCHICAL_ACCESS_KEY
          }}
        ABFS_HIERARCHICAL_ACCOUNT: ${{ vars.AZURE_ABFS_HIERARCHICAL_ACCOUNT }}
        ABFS_OAUTH_CLIENT_ID: ${{ vars.AZURE_ABFS_OAUTH_CLIENT_ID }}
        ABFS_OAUTH_CLIENT_SECRET: ${{ secrets.AZURE_ABFS_OAUTH_CLIENT_SECRET }}
        ABFS_OAUTH_TENANT_ID: ${{ vars.AZURE_ABFS_OAUTH_TENANT_ID }}
      id: tests-azure
      if: contains(matrix.modules, 'trino-filesystem-azure') && contains(matrix.profile,
        'cloud-tests') && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || env.ABFS_FLAT_ACCESS_KEY
        != '' || env.ABFS_HIERARCHICAL_ACCESS_KEY != '' || env.ABFS_OAUTH_CLIENT_SECRET
        != '')
      name: Azure FileSystem Cloud Tests
      run: '$MAVEN test ${MAVEN_TEST} -pl ${{ matrix.modules }} ${{ format(''-P {0}'',
        matrix.profile) }}

        '
    - continue-on-error: true
      env:
        GCP_CREDENTIALS_KEY: ${{ secrets.GCP_CREDENTIALS_KEY }}
      id: tests-gcs
      if: contains(matrix.modules, 'trino-filesystem-gcs') && contains(matrix.profile,
        'cloud-tests') && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || env.GCP_CREDENTIALS_KEY
        != '')
      name: GCS FileSystem Cloud Tests
      run: '$MAVEN test ${MAVEN_TEST} -pl ${{ matrix.modules }} ${{ format(''-P {0}'',
        matrix.profile) }}

        '
    - continue-on-error: true
      env:
        ABFS_ACCESSKEY: ${{ secrets.AZURE_ABFS_HIERARCHICAL_ACCESS_KEY }}
        ABFS_ACCOUNT: ${{ vars.AZURE_ABFS_HIERARCHICAL_ACCOUNT }}
        ABFS_CONTAINER: ${{ vars.AZURE_ABFS_HIERARCHICAL_CONTAINER }}
        AWS_ACCESS_KEY_ID: ${{ vars.TRINO_AWS_ACCESS_KEY_ID }}
        AWS_REGION: ${{ vars.TRINO_AWS_REGION }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.TRINO_AWS_SECRET_ACCESS_KEY }}
        GCP_CREDENTIALS_KEY: ${{ secrets.GCP_CREDENTIALS_KEY }}
        GCP_STORAGE_BUCKET: ${{ vars.GCP_STORAGE_BUCKET }}
        S3_BUCKET: ${{ vars.TRINO_S3_BUCKET }}
      id: tests-delta
      if: contains(matrix.modules, 'trino-delta-lake') && contains(matrix.profile,
        'cloud-tests') && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || env.ABFS_ACCOUNT
        != '' || env.ABFS_CONTAINER != '' || env.ABFS_ACCESSKEY != '' || env.AWS_ACCESS_KEY_ID
        != '' || env.AWS_SECRET_ACCESS_KEY != '' || env.GCP_CREDENTIALS_KEY != '')
      name: Cloud Delta Lake Tests
      run: "$MAVEN test ${MAVEN_TEST} ${{ format('-P {0}', matrix.profile) }} -pl\
        \ :trino-delta-lake \\\n  -Dtesting.azure-abfs-container=\"${ABFS_CONTAINER}\"\
        \ \\\n  -Dtesting.azure-abfs-account=\"${ABFS_ACCOUNT}\" \\\n  -Dtesting.azure-abfs-access-key=\"\
        ${ABFS_ACCESSKEY}\" \\\n  -Dtesting.gcp-storage-bucket=\"${GCP_STORAGE_BUCKET}\"\
        \ \\\n  -Dtesting.gcp-credentials-key=\"${GCP_CREDENTIALS_KEY}\"\n"
    - continue-on-error: true
      env:
        MEMSQL_LICENSE: ${{ secrets.MEMSQL_LICENSE }}
      id: tests-memsql
      if: matrix.modules == 'plugin/trino-singlestore' && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS
        != '' || env.MEMSQL_LICENSE != '')
      name: Memsql Tests
      run: '$MAVEN test ${MAVEN_TEST} -pl :trino-singlestore -Dmemsql.license=${MEMSQL_LICENSE}

        '
    - continue-on-error: true
      env:
        BIGQUERY_CREDENTIALS_KEY: ${{ secrets.BIGQUERY_CREDENTIALS_KEY }}
        GCP_STORAGE_BUCKET: ${{ vars.GCP_STORAGE_BUCKET }}
      id: tests-bq
      if: matrix.modules == 'plugin/trino-bigquery' && !contains(matrix.profile, 'cloud-tests-2')
        && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || env.BIGQUERY_CREDENTIALS_KEY
        != '')
      name: Cloud BigQuery Tests
      run: "$MAVEN test ${MAVEN_TEST} -pl :trino-bigquery -Pcloud-tests-1 \\\n  -Dbigquery.credentials-key=\"\
        ${BIGQUERY_CREDENTIALS_KEY}\" \\\n  -Dtesting.gcp-storage-bucket=\"${GCP_STORAGE_BUCKET}\"\
        \n"
    - continue-on-error: true
      env:
        BIGQUERY_CREDENTIALS_KEY: ${{ secrets.BIGQUERY_CREDENTIALS_KEY }}
        GCP_STORAGE_BUCKET: ${{ vars.GCP_STORAGE_BUCKET }}
      id: tests-bq-smoke
      if: matrix.modules == 'plugin/trino-bigquery' && contains(matrix.profile, 'cloud-tests-2')
        && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || env.BIGQUERY_CREDENTIALS_KEY
        != '')
      name: Cloud BigQuery Smoke Tests
      run: "$MAVEN test ${MAVEN_TEST} -pl :trino-bigquery -Pcloud-tests-2 \\\n  -Dbigquery.credentials-key=\"\
        ${BIGQUERY_CREDENTIALS_KEY}\" \\\n  -Dtesting.gcp-storage-bucket=\"${GCP_STORAGE_BUCKET}\"\
        \ \\\n  -Dtesting.alternate-bq-project-id=bigquery-cicd-alternate\n"
    - continue-on-error: true
      env:
        BIGQUERY_CASE_INSENSITIVE_CREDENTIALS_KEY: ${{ secrets.BIGQUERY_CASE_INSENSITIVE_CREDENTIALS_KEY
          }}
      id: tests-bq-ci
      if: matrix.modules == 'plugin/trino-bigquery' && !contains(matrix.profile, 'cloud-tests-2')
        && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || env.BIGQUERY_CASE_INSENSITIVE_CREDENTIALS_KEY
        != '')
      name: Cloud BigQuery Case Insensitive Mapping Tests
      run: '$MAVEN test ${MAVEN_TEST} -pl :trino-bigquery -Pcloud-tests-case-insensitive-mapping
        -Dbigquery.credentials-key="${BIGQUERY_CASE_INSENSITIVE_CREDENTIALS_KEY}"

        '
    - continue-on-error: true
      env:
        SNOWFLAKE_DATABASE: ${{ vars.SNOWFLAKE_DATABASE }}
        SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        SNOWFLAKE_ROLE: ${{ vars.SNOWFLAKE_ROLE }}
        SNOWFLAKE_URL: ${{ vars.SNOWFLAKE_URL }}
        SNOWFLAKE_USER: ${{ vars.SNOWFLAKE_USER }}
        SNOWFLAKE_WAREHOUSE: ${{ vars.SNOWFLAKE_WAREHOUSE }}
      id: tests-snowflake
      if: matrix.modules == 'plugin/trino-snowflake' && contains(matrix.profile, 'cloud-tests')
        && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || env.SNOWFLAKE_URL != '')
      name: Cloud Snowflake Tests
      run: "$MAVEN test ${MAVEN_TEST} -pl :trino-snowflake -Pcloud-tests \\\n  -Dsnowflake.test.server.url=\"\
        ${SNOWFLAKE_URL}\" \\\n  -Dsnowflake.test.server.user=\"${SNOWFLAKE_USER}\"\
        \ \\\n  -Dsnowflake.test.server.password=\"${SNOWFLAKE_PASSWORD}\" \\\n  -Dsnowflake.test.server.database=\"\
        ${SNOWFLAKE_DATABASE}\" \\\n  -Dsnowflake.test.server.role=\"${SNOWFLAKE_ROLE}\"\
        \ \\\n  -Dsnowflake.test.server.warehouse=\"${SNOWFLAKE_WAREHOUSE}\"\n"
    - continue-on-error: true
      env:
        ABFS_ACCESS_KEY: ${{ secrets.AZURE_ABFS_HIERARCHICAL_ACCESS_KEY }}
        ABFS_ACCOUNT: ${{ vars.AZURE_ABFS_HIERARCHICAL_ACCOUNT }}
        ABFS_CONTAINER: ${{ vars.AZURE_ABFS_HIERARCHICAL_CONTAINER }}
        AWS_ACCESS_KEY_ID: ${{ vars.TRINO_AWS_ACCESS_KEY_ID }}
        AWS_REGION: ${{ vars.TRINO_AWS_REGION }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.TRINO_AWS_SECRET_ACCESS_KEY }}
        GCP_CREDENTIALS_KEY: ${{ secrets.GCP_CREDENTIALS_KEY }}
        GCP_STORAGE_BUCKET: ${{ vars.GCP_STORAGE_BUCKET }}
        S3_BUCKET: ${{ vars.TRINO_S3_BUCKET }}
        SNOWFLAKE_CATALOG_S3_ACCESS_KEY_ID: ${{ vars.SNOWFLAKE_CATALOG_S3_ACCESS_KEY_ID
          }}
        SNOWFLAKE_CATALOG_S3_REGION: ${{ vars.SNOWFLAKE_CATALOG_S3_REGION }}
        SNOWFLAKE_CATALOG_S3_SECRET_ACCESS_KEY: ${{ secrets.SNOWFLAKE_CATALOG_S3_SECRET_ACCESS_KEY
          }}
        SNOWFLAKE_CATALOG_SCHEMA: ${{ vars.SNOWFLAKE_CATALOG_SCHEMA }}
        SNOWFLAKE_DATABASE: ${{ vars.SNOWFLAKE_DATABASE }}
        SNOWFLAKE_EXTERNAL_VOLUME: ${{ vars.SNOWFLAKE_EXTERNAL_VOLUME }}
        SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        SNOWFLAKE_ROLE: ${{ vars.SNOWFLAKE_ROLE }}
        SNOWFLAKE_URL: ${{ vars.SNOWFLAKE_URL }}
        SNOWFLAKE_USER: ${{ vars.SNOWFLAKE_USER }}
        SNOWFLAKE_WAREHOUSE: ${{ vars.SNOWFLAKE_WAREHOUSE }}
      id: tests-iceberg
      if: contains(matrix.modules, 'trino-iceberg') && contains(matrix.profile, 'cloud-tests')
        && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS != '' || env.AWS_ACCESS_KEY_ID !=
        '' || env.AWS_SECRET_ACCESS_KEY != '' || env.GCP_CREDENTIALS_KEY != '')
      name: Iceberg Cloud Tests
      run: "$MAVEN test ${MAVEN_TEST} -pl :trino-iceberg ${{ format('-P {0}', matrix.profile)\
        \ }} \\\n  -Dtesting.gcp-storage-bucket=\"${GCP_STORAGE_BUCKET}\" \\\n  -Dtesting.gcp-credentials-key=\"\
        ${GCP_CREDENTIALS_KEY}\" \\\n  -Dtesting.azure-abfs-container=\"${ABFS_CONTAINER}\"\
        \ \\\n  -Dtesting.azure-abfs-account=\"${ABFS_ACCOUNT}\" \\\n  -Dtesting.azure-abfs-access-key=\"\
        ${ABFS_ACCESS_KEY}\" \\\n  -Dtesting.snowflake.catalog.user=\"${SNOWFLAKE_USER}\"\
        \ \\\n  -Dtesting.snowflake.catalog.password=\"${SNOWFLAKE_PASSWORD}\" \\\n\
        \  -Dtesting.snowflake.catalog.account-url=\"${SNOWFLAKE_URL}\" \\\n  -Dtesting.snowflake.catalog.database=\"\
        ${SNOWFLAKE_DATABASE}\" \\\n  -Dtesting.snowflake.catalog.schema=\"${SNOWFLAKE_CATALOG_SCHEMA}\"\
        \ \\\n  -Dtesting.snowflake.catalog.role=\"${SNOWFLAKE_ROLE}\" \\\n  -Dtesting.snowflake.catalog.warehouse=\"\
        ${SNOWFLAKE_WAREHOUSE}\" \\\n  -Dtesting.snowflake.catalog.s3.access-key=\"\
        ${SNOWFLAKE_CATALOG_S3_ACCESS_KEY_ID}\" \\\n  -Dtesting.snowflake.catalog.s3.secret-key=\"\
        ${SNOWFLAKE_CATALOG_S3_SECRET_ACCESS_KEY}\" \\\n  -Dtesting.snowflake.catalog.s3.external.volume=\"\
        ${SNOWFLAKE_EXTERNAL_VOLUME}\" \\\n  -Dtesting.snowflake.catalog.s3.region=\"\
        ${SNOWFLAKE_CATALOG_S3_REGION}\"\n"
    - continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ vars.REDSHIFT_AWS_ACCESS_KEY_ID }}
        AWS_REGION: ${{ vars.REDSHIFT_AWS_REGION }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.REDSHIFT_AWS_SECRET_ACCESS_KEY }}
        REDSHIFT_IAM_ROLES: ${{ vars.REDSHIFT_IAM_ROLES }}
        REDSHIFT_S3_TPCH_TABLES_ROOT: ${{ vars.REDSHIFT_S3_TPCH_TABLES_ROOT }}
        REDSHIFT_SUBNET_GROUP_NAME: ${{ vars.REDSHIFT_SUBNET_GROUP_NAME }}
        REDSHIFT_VPC_SECURITY_GROUP_IDS: ${{ vars.REDSHIFT_VPC_SECURITY_GROUP_IDS
          }}
      id: tests-redshift
      if: contains(matrix.modules, 'trino-redshift') && (contains(matrix.profile,
        'cloud-tests') || contains(matrix.profile, 'fte-tests')) && (env.CI_SKIP_SECRETS_PRESENCE_CHECKS
        != '' || env.AWS_ACCESS_KEY_ID != '' || env.REDSHIFT_SUBNET_GROUP_NAME !=
        '')
      name: Cloud Redshift Tests ${{ matrix.profile }}
      run: "source .github/bin/redshift/setup-aws-redshift.sh\n\n$MAVEN test ${MAVEN_TEST}\
        \ -pl ${{ matrix.modules }} ${{ format('-P {0}', matrix.profile) }} \\\n \
        \ -Dtest.redshift.jdbc.user=\"${REDSHIFT_USER}\" \\\n  -Dtest.redshift.jdbc.password=\"\
        ${REDSHIFT_PASSWORD}\" \\\n  -Dtest.redshift.jdbc.endpoint=\"${REDSHIFT_ENDPOINT}:${REDSHIFT_PORT}/\"\
        \ \\\n  -Dtest.redshift.s3.tpch.tables.root=\"${REDSHIFT_S3_TPCH_TABLES_ROOT}\"\
        \ \\\n  -Dtest.redshift.iam.role=\"${REDSHIFT_IAM_ROLES}\" \\\n  -Dtest.redshift.aws.region=\"\
        ${AWS_REGION}\" \\\n  -Dtest.redshift.aws.access-key=\"${AWS_ACCESS_KEY_ID}\"\
        \ \\\n  -Dtest.redshift.aws.secret-key=\"${AWS_SECRET_ACCESS_KEY}\"\n"
    - continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ vars.REDSHIFT_AWS_ACCESS_KEY_ID }}
        AWS_REGION: ${{ vars.REDSHIFT_AWS_REGION }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.REDSHIFT_AWS_SECRET_ACCESS_KEY }}
      if: always()
      name: Cleanup ephemeral Redshift Cluster
      run: .github/bin/redshift/delete-aws-redshift.sh
    - continue-on-error: true
      if: always()
      name: Sanitize artifact name
      run: '# Generate a valid artifact name and make it available to next steps as

        # an environment variable ARTIFACT_NAME

        # ", :, <, >, |, *, ?, \, / are not allowed in artifact names, replace it
        with an underscore

        name=$(echo -n "${{ matrix.modules }}, ${{ matrix.profile }}, ${{ matrix.jdk
        }}" | sed -e ''s/[":<>|\*\?\\\/]/_/g'')

        # final artifact name can''t be longer than 128 characters

        echo "ARTIFACT_NAME=${name:0:100}" >> $GITHUB_ENV

        '
    - continue-on-error: true
      if: always()
      name: Upload test results
      uses: ./.github/actions/process-test-results
      with:
        artifact-name: ${{ env.ARTIFACT_NAME }}
        has-failed-tests: "${{ steps.tests.outcome == 'failure'\n  || steps.tests-hdfs-isolated.outcome\
          \ == 'failure'\n  || steps.tests-hdfs.outcome == 'failure'\n  || steps.tests-s3.outcome\
          \ == 'failure'\n  || steps.tests-azure.outcome == 'failure'\n  || steps.tests-gcs.outcome\
          \ == 'failure'\n  || steps.tests-delta.outcome == 'failure'\n  || steps.tests-memsql.outcome\
          \ == 'failure'\n  || steps.tests-bq.outcome == 'failure'\n  || steps.tests-bq-ci.outcome\
          \ == 'failure'\n  || steps.tests-bq-smoke.outcome == 'failure'\n  || steps.tests-iceberg.outcome\
          \ == 'failure'\n  || steps.tests-redshift.outcome == 'failure'\n  || steps.tests-snowflake.outcome\
          \ == 'failure'\n}}"
        upload-heap-dump: ${{ env.SECRETS_PRESENT == '' && github.event_name == 'pull_request'
          && github.event.pull_request.head.repo.full_name != github.repository }}
    - continue-on-error: true
      if: failure() && github.event_name == 'repository_dispatch' && github.event.client_payload.slash_command.args.named.sha
        != '' && github.event.client_payload.pull_request.head.sha == github.event.client_payload.slash_command.args.named.sha
      name: Update PR check
      uses: ./.github/actions/update-check
      with:
        check_name: ${{ github.job }} with secrets
        conclusion: ${{ job.status }}
        github_token: ${{ secrets.GITHUB_TOKEN }}
        pull_request_number: ${{ github.event.client_payload.pull_request.number }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.build-test-matrix.outputs.matrix) }}
    timeout-minutes: 60
  test-jdbc-compatibility:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      timeout-minutes: 10
      uses: ./.github/actions/setup
      with:
        cache: restore
    - continue-on-error: true
      name: Maven Install
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN clean install ${MAVEN_FAST_INSTALL} ${MAVEN_GIB} -Dgib.logImpactedTo=gib-impacted.log
        -pl ''!:trino-docs,!:trino-server,!:trino-server-rpm''

        '
    - continue-on-error: true
      id: tests-old
      name: Test old JDBC vs current server
      run: "if [ ! -f gib-impacted.log ] || grep -q testing/trino-test-jdbc-compatibility-old-driver\
        \ gib-impacted.log; then\n  testing/trino-test-jdbc-compatibility-old-driver/bin/run_tests.sh\n\
        fi\n"
    - continue-on-error: true
      id: tests-current
      if: always()
      name: Test current JDBC vs old server
      run: "if [ ! -f gib-impacted.log ] || grep -q testing/trino-test-jdbc-compatibility-old-server\
        \ gib-impacted.log; then\n  $MAVEN test ${MAVEN_TEST} -pl :trino-test-jdbc-compatibility-old-server\n\
        fi\n"
    - continue-on-error: true
      if: always()
      name: Upload test results
      uses: ./.github/actions/process-test-results
      with:
        has-failed-tests: ${{ steps.tests-old.outcome == 'failure' || steps.tests-current.outcome
          == 'failure' }}
        upload-heap-dump: ${{ env.SECRETS_PRESENT == '' && github.event_name == 'pull_request'
          && github.event.pull_request.head.repo.full_name != github.repository }}
    timeout-minutes: 30
  test-other-modules:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      timeout-minutes: 10
      uses: ./.github/actions/setup
      with:
        cache: restore
        cleanup-node: true
    - continue-on-error: true
      name: Maven Install
      run: 'export MAVEN_OPTS="${MAVEN_INSTALL_OPTS}"

        $MAVEN clean install ${MAVEN_FAST_INSTALL} ${MAVEN_GIB} -pl ''!:trino-docs,!:trino-server,!:trino-server-rpm''

        '
    - continue-on-error: true
      id: tests
      name: Maven Tests
      run: "$MAVEN test ${MAVEN_TEST} -pl '\n  !:trino-accumulo,\n  !:trino-base-jdbc,\n\
        \  !:trino-bigquery,\n  !:trino-cassandra,\n  !:trino-clickhouse,\n  !:trino-delta-lake,\n\
        \  !:trino-docs,\n  !:trino-druid,\n  !:trino-elasticsearch,\n  !:trino-faulttolerant-tests,\n\
        \  !:trino-filesystem,\n  !:trino-filesystem-azure,\n  !:trino-filesystem-gcs,\n\
        \  !:trino-filesystem-manager,\n  !:trino-filesystem-s3,\n  !:trino-google-sheets,\n\
        \  !:trino-hdfs,\n  !:trino-hive,\n  !:trino-hudi,\n  !:trino-iceberg,\n \
        \ !:trino-ignite,\n  !:trino-jdbc,\n  !:trino-kafka,\n  !:trino-kudu,\n  !:trino-main,\n\
        \  !:trino-mariadb,\n  !:trino-memory,\n  !:trino-mongodb,\n  !:trino-mysql,\n\
        \  !:trino-opensearch,\n  !:trino-oracle,\n  !:trino-orc,\n  !:trino-parquet,\n\
        \  !:trino-phoenix5,\n  !:trino-pinot,\n  !:trino-postgresql,\n  !:trino-raptor-legacy,\n\
        \  !:trino-redis,\n  !:trino-redshift,\n  !:trino-resource-group-managers,\n\
        \  !:trino-server,\n  !:trino-server-rpm,\n  !:trino-singlestore,\n  !:trino-snowflake,\n\
        \  !:trino-sqlserver,\n  !:trino-test-jdbc-compatibility-old-server,\n  !:trino-tests,\n\
        \  !:trino-thrift'\n"
    - continue-on-error: true
      if: always()
      name: Upload test results
      uses: ./.github/actions/process-test-results
      with:
        has-failed-tests: ${{ steps.tests.outcome == 'failure' }}
        upload-heap-dump: ${{ env.SECRETS_PRESENT == '' && github.event_name == 'pull_request'
          && github.event.pull_request.head.repo.full_name != github.repository }}
    timeout-minutes: 60
  web-ui-checks:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: "${{ github.event_name == 'repository_dispatch' &&\n    github.event.client_payload.pull_request.head.sha\
          \ == github.event.client_payload.slash_command.args.named.sha &&\n    format('refs/pull/{0}/head',\
          \ github.event.client_payload.pull_request.number) || '' }}\n"
    - continue-on-error: true
      name: Web UI Checks
      run: core/trino-main/bin/check_webui.sh
    timeout-minutes: 30
name: ci
on:
  repository_dispatch:
    types: trigger-ga___ci.yml
